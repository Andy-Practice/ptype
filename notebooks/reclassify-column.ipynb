{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting an alternative type for a column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes ptype infers a type for a column which we know to be incorrect; we can select a different column type, and still take advantage of ptype per-row type inference (conditional on the new type of the column) to identify anomalous and missing values.\n",
    "\n",
    "We present two usecases which are summarized below:\n",
    "- A toy example: We employ ptype on a toy example constructed using 4-digit formatted years as normal values and a 2-digit year as an anomalous entry. We assume that the user runs ptype on this data frame and then inspects the inferred schema. The schema denotes that the column is classified as integer whereas the correct column type is date-iso-8601. Therefore, the user asks ptype to reclassify this column as date-iso-8601 and notices that this feedback lets ptype detect anomalous entries which could not be detected before.\n",
    "- A real-world example: \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preamble to run notebook in context of source package.\n",
    "import sys\n",
    "sys.path.insert(0, '../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcdefaults()\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from ptype.Ptype import Ptype\n",
    "from utils import plot_column_type_posterior, plot_arff_type_posterior, subsample_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Toy Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ['1991', '1992', '1993', '1994', '1995', '1996', '1997', '1998', '90']\n",
    "column = 'year'\n",
    "\n",
    "df = pd.DataFrame(x, dtype='str', columns=[column])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptype = Ptype()\n",
    "\n",
    "ptype.schema_fit(df)\n",
    "ptype.show_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptype.cols[column].reclassify('date-iso-8601')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptype.show_schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real-world Example\n",
    "In this example, we use the Grub Damage dataset to analyze the relationship between grass grub numbers, irrigation and damage.\n",
    "\n",
    "Let us simply the problem and consider the task of finding the association between the zone and GG_new columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/grub-damage.csv', encoding=\"ISO-8859-1\",dtype='str')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we use ptype to inspect the properties of this dataset and transform it accordingly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ptype = Ptype()\n",
    "\n",
    "schema = ptype.schema_fit(df)\n",
    "ptype.show_schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, ptype predicts the data type of the zone column as boolean and labels the values of C and M as anomalies. Note that we can confirm that these values are normal values using the corresponding metadata, which states \"8. zone - position of paddock (F: foothills, M: midplain, C: coastal) - enumerated\".\n",
    "\n",
    "If we are not interacting with ptype, we would obtain the following data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transformed = ptype.schema_transform(df, schema)\n",
    "df_transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, the Cramers V statistic between zone and GG_new columns would be undefined due to anomalous values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NBVAL_IGNORE_OUTPUT\n",
    "\n",
    "import scipy.stats as ss\n",
    "\n",
    "def cramers_corrected_stat(x, y):\n",
    "    \"\"\" calculate Cramers V statistic for categorial-categorial association.\n",
    "        uses correction from Bergsma and Wicher, \n",
    "        Journal of the Korean Statistical Society 42 (2013): 323-328\n",
    "    \"\"\"\n",
    "    confusion_matrix = pd.crosstab(x, y)\n",
    "    chi2 = ss.chi2_contingency(confusion_matrix)[0]\n",
    "    n = confusion_matrix.sum().sum()\n",
    "    phi2 = chi2/n\n",
    "    r,k = confusion_matrix.shape\n",
    "    phi2corr = max(0, phi2 - ((k-1)*(r-1))/(n-1))    \n",
    "    rcorr = r - ((r-1)**2)/(n-1)\n",
    "    kcorr = k - ((k-1)**2)/(n-1)\n",
    "    return np.sqrt(phi2corr / min( (kcorr-1), (rcorr-1)))\n",
    "\n",
    "\n",
    "cramers_corrected_stat(df_transformed['zone'], df_transformed['GG_new'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now interact with ptype to fix its predictions for the zone column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptype.cols['zone'].reclassify('string')\n",
    "ptype.show_schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the column type prediction of the zone column is now correct. Moreover, the row type predictions are also updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use the updated schema\n",
    "schema = ptype.cols\n",
    "df_transformed = ptype.schema_transform(df, schema)\n",
    "df_transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now calculate the Cramers V statistic as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cramers_corrected_stat(df_transformed['zone'], df_transformed['GG_new'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
